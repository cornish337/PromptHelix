# PromptHelix Documentation

This document provides a more detailed overview of the internal structure, components, and advanced testing procedures for PromptHelix. For general information, getting started, setup, and deployment, please refer to the main [README.md](../../README.md) in the root directory.

## Project Structure

For overall project setup, deployment, and basic usage, please refer to the main [README.md](../../README.md).

The core components of PromptHelix are organized as follows:

-   `prompthelix/agents/`: Contains different types of AI agents (Architect, Critic, etc.).
-   `prompthelix/api/`: Defines the FastAPI endpoints and routing.
-   `prompthelix/cli.py`: Command-line interface entry point and commands.
-   `prompthelix/config.py`: Application configuration settings. See the main `README.md` for how to configure API keys and database URLs via environment variables.
-   `prompthelix/core/`: Core functionalities like the Prompt DNA system.
-   `prompthelix/database/`: Database models (SQLAlchemy), session management, and initialization.
-   `prompthelix/docs/`: Project documentation, including this file and `agent_specifications.md`.
-   `prompthelix/evaluation/`: Modules for evaluating prompt performance.
-   `prompthelix/evolution/`: Core logic for the genetic algorithm (chromosomes, operators, population), previously `prompthelix/genetics/`.
-   `prompthelix/llm_integrations/`: Modules for interacting with various LLM providers.
-   `prompthelix/main.py`: Main FastAPI application entry point.
-   `prompthelix/schemas/`: Pydantic schemas for data validation and serialization.
-   `prompthelix/services/`: Business logic and services.
-   `prompthelix/tests/`: Unit and integration tests.
    -   `unit/`: Contains unit tests for individual components.
    -   `integration/`: Contains integration tests.
-   `prompthelix/ui/`: HTML templates and static files for the web UI.
-   `prompthelix/utils/`: Utility functions and helpers.
-   `.env.example`: Example environment variable file.
-   `alembic/`: Alembic migration scripts and configuration (if used for DB migrations).
-   `main.py`: (Potentially a root-level script, verify if it's different from `prompthelix/main.py` or if this is a typo in original, assuming `prompthelix/main.py` is the primary one).
-   `requirements.txt`: Project dependencies.
-   `Dockerfile`: Docker configuration for containerization.
-   `CONTRIBUTING.md`: Guidelines for contributing (in root directory).
-   `LICENSE`: Project license information (in root directory).

*Note: The project structure might evolve. Refer to the actual directory layout for the most current information.*

## Implemented Agents

The PromptHelix system is designed around a collection of specialized AI agents that collaborate to generate, refine, and evaluate prompts.

-   **`PromptArchitectAgent`**: Designs the initial genetic structure of prompts based on user requirements, system goals, or existing successful prompt patterns.
-   **`PromptCriticAgent`**: Evaluates and critiques prompts based on their structure, content, and adherence to best practices, without necessarily executing them (acting as a "static analyzer").
-   **`StyleOptimizerAgent`**: Refines prompts to enhance their style, tone, clarity, and persuasiveness, often based on specific target audience or desired communication effect.
-   **`ResultsEvaluatorAgent`**: Assesses the quality, relevance, and effectiveness of the outputs generated by an LLM in response to a given prompt.
-   **`MetaLearnerAgent`**: Analyzes the overall performance of the prompt generation and optimization process over time to provide higher-level guidance and adapt strategies.
-   **`DomainExpertAgent`**: Provides domain-specific knowledge, constraints, terminology, and evaluation criteria to other agents.

### Agent Functionality Notes
The current implementations of these agents are functional placeholders. They utilize mock data (e.g., for templates, critique rules, style rules, domain knowledge) and simplified internal logic. This approach is intended to establish the foundational framework of the multi-agent system and demonstrate the intended interactions and data flows. Future development will involve replacing mock data with configurable sources and implementing more sophisticated algorithms and machine learning models within each agent.

### Message Flow

Agents interact through an asynchronous message bus. Agents subscribe to message
types they care about and broadcast results for others to consume. The
`ResultsEvaluatorAgent` and `PromptCriticAgent` broadcast `evaluation_result` and
`critique_result` messages respectively. The `MetaLearnerAgent` listens for these
messages and updates its knowledge base whenever new feedback arrives.

## Testing

Unit tests for the core placeholder functionalities of each agent and the genetic algorithm components are located in the `prompthelix/tests/unit/` directory. Each component has its own test file (e.g., `test_architect_agent.py`, `test_genetic_operators.py`, etc.) that verifies its basic operations.

To run the tests, navigate to the root directory of the project and use a test runner like Python's `unittest` module. For example:
```bash
python -m unittest discover -s prompthelix/tests/unit
```
(Further details on test execution and integration tests will be added as the project matures.)

### LLM Connectivity Test

A utility script `prompthelix/tests/test_llm_connectivity.py` is provided to test connectivity to a specified Large Language Model (LLM) provider and model. This script helps ensure that your environment is correctly configured and that the LLM services are accessible.

**Running the Script:**

You can run the script from the command line using Python:

```bash
python prompthelix/tests/test_llm_connectivity.py [options]
```

**Command-Line Arguments:**

-   `--provider`: Specifies the LLM provider.
    -   Default: `openai`
    -   Example: `openai`, `anthropic`, `google` (adjust based on actual provider keys in `llm_integrations`)
-   `--model`: Specifies the model name for the chosen provider.
    -   Default: `gpt-3.5-turbo`
    -   Example: `gpt-3.5-turbo` (for OpenAI), `claude-2` (for Anthropic), `gemini-pro` (for Google)

**Important Note:**
This script requires the appropriate API key environment variables to be set for the provider you are testing (e.g., `OPENAI_API_KEY`, `ANTHROPIC_API_KEY`, `GOOGLE_API_KEY`). Refer to the "Environment Variable Setup" section in the main `README.md` for details on how to set these.

**Usage Examples:**

```bash
python -m prompthelix.tests.test_llm_connectivity --provider openai --model gpt-3.5-turbo
```

```bash
python -m prompthelix.tests.test_llm_connectivity --provider anthropic --model claude-2
```

## Genetic Algorithm Engine

PromptHelix employs a Genetic Algorithm (GA) to iteratively evolve and optimize prompts. This engine uses concepts like selection, crossover, and mutation to refine a population of prompts over generations, aiming to enhance their effectiveness based on defined fitness criteria. The GA is designed to interact with various specialized agents for tasks like initial prompt creation, fitness evaluation (based on LLM output simulation), and potentially for more advanced "smart" mutations.

For a detailed explanation of the GA components and flow, please see:
`[Read more about the Genetic Algorithm](./genetic_algorithm.md)`

## Running Parts of the Application

For instructions on running the main Web UI or the CLI for tasks like running the genetic algorithm or tests, please refer to the main `README.md` in the root directory. The main `README.md` covers:

*   Setting up the virtual environment.
*   Installing dependencies.
*   Setting up environment variables (including API keys).
*   Running the FastAPI web server.
*   Using the `prompthelix.cli` for various operations.

The `prompthelix/orchestrator.py` mentioned in previous versions of this document has likely been integrated into or superseded by the CLI and API functionalities described in the main `README.md`.

## Future Directions
(This section can be maintained here if it pertains to more granular, internal development plans not covered in the main README.)

## License

This project is licensed under the MIT License. See the [LICENSE](../../LICENSE) file in the root directory for details.

## Contributing

We welcome contributions! Please see our [CONTRIBUTING.md](../../CONTRIBUTING.md) file in the root directory for detailed guidelines.
