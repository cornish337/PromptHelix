# PromptHelix

A Python framework for AI prompt generation and optimization using a Prompt DNA System.

## Project Structure

-   `prompthelix/agents/`: Contains different types of AI agents (Architect, Critic, etc.).
-   `prompthelix/api/`: Defines the FastAPI endpoints and routing.
-   `prompthelix/config.py`: Application configuration settings.
-   `prompthelix/docs/`: Project documentation.
    -   `agent_specifications.md`: Detailed specifications for each agent.
-   `prompthelix/evaluation/`: Modules for evaluating prompt performance (placeholder).
-   `prompthelix/genetics/`: Core logic for the genetic algorithm (chromosomes, operators, population).
-   `prompthelix/main.py`: Main FastAPI application entry point.
-   `prompthelix/models/`: Data models (SQLAlchemy or Pydantic, currently placeholders).
-   `prompthelix/services/`: Business logic and services (placeholder).
-   `prompthelix/tests/`: Unit and integration tests.
    -   `unit/`: Contains unit tests for individual components, including each agent.
-   `prompthelix/utils/`: Utility functions and helpers (placeholder).
-   `setup.py`: Project setup script.
-   `requirements.txt`: Project dependencies.
-   `Dockerfile`: Docker configuration for containerization.

## Implemented Agents

The PromptHelix system is designed around a collection of specialized AI agents that collaborate to generate, refine, and evaluate prompts.

-   **`PromptArchitectAgent`**: Designs the initial genetic structure of prompts based on user requirements, system goals, or existing successful prompt patterns.
-   **`PromptCriticAgent`**: Evaluates and critiques prompts based on their structure, content, and adherence to best practices, without necessarily executing them (acting as a "static analyzer").
-   **`StyleOptimizerAgent`**: Refines prompts to enhance their style, tone, clarity, and persuasiveness, often based on specific target audience or desired communication effect.
-   **`ResultsEvaluatorAgent`**: Assesses the quality, relevance, and effectiveness of the outputs generated by an LLM in response to a given prompt.
-   **`MetaLearnerAgent`**: Analyzes the overall performance of the prompt generation and optimization process over time to provide higher-level guidance and adapt strategies.
-   **`DomainExpertAgent`**: Provides domain-specific knowledge, constraints, terminology, and evaluation criteria to other agents.

### Agent Functionality Notes
The current implementations of these agents are functional placeholders. They utilize mock data (e.g., for templates, critique rules, style rules, domain knowledge) and simplified internal logic. This approach is intended to establish the foundational framework of the multi-agent system and demonstrate the intended interactions and data flows. Future development will involve replacing mock data with configurable sources and implementing more sophisticated algorithms and machine learning models within each agent.

## Testing

Unit tests for the core placeholder functionalities of each agent and the genetic algorithm components are located in the `prompthelix/tests/unit/` directory. Each component has its own test file (e.g., `test_architect_agent.py`, `test_genetic_operators.py`, etc.) that verifies its basic operations.

To run the tests, navigate to the root directory of the project and use a test runner like Python's `unittest` module. For example:
```bash
python -m unittest discover -s prompthelix/tests/unit
```
(Further details on test execution and integration tests will be added as the project matures.)

### LLM Connectivity Test

A utility script `prompthelix/tests/test_llm_connectivity.py` is provided to test connectivity to a specified Large Language Model (LLM) provider and model. This script helps ensure that your environment is correctly configured and that the LLM services are accessible.

**Running the Script:**

You can run the script from the command line using Python:

```bash
python prompthelix/tests/test_llm_connectivity.py [options]
```

**Command-Line Arguments:**

-   `--provider`: Specifies the LLM provider.
    -   Default: `openai`
    -   Example: `openai`, `claude`
-   `--model`: Specifies the model name for the chosen provider.
    -   Default: `gpt-3.5-turbo`
    -   Example: `gpt-3.5-turbo`, `claude-2`

**Usage Examples:**

```bash
python prompthelix/tests/test_llm_connectivity.py --provider openai --model gpt-3.5-turbo
```

```bash
python prompthelix/tests/test_llm_connectivity.py --provider claude --model claude-2
```

## Genetic Algorithm Engine

PromptHelix employs a Genetic Algorithm (GA) to iteratively evolve and optimize prompts. This engine uses concepts like selection, crossover, and mutation to refine a population of prompts over generations, aiming to enhance their effectiveness based on defined fitness criteria. The GA is designed to interact with various specialized agents for tasks like initial prompt creation, fitness evaluation (based on LLM output simulation), and potentially for more advanced "smart" mutations.

For a detailed explanation of the GA components and flow, please see:
`[Read more about the Genetic Algorithm](./genetic_algorithm.md)`

## Running the Project

Currently, the primary way to see the system in action (beyond unit tests) is by running the placeholder genetic algorithm orchestrator.

### Running the Genetic Algorithm Orchestrator

The `prompthelix/orchestrator.py` script provides a basic command-line demonstration of the GA loop. It initializes the necessary agents and GA components, creates an initial population of prompts, and runs the evolutionary process for a predefined number of generations.

To run the orchestrator:
1.  Ensure you are in the root directory of the `prompthelix` project.
2.  Make sure your Python environment has the project and its dependencies installed (e.g., by running `pip install .` or `pip install -e .` if you have a `setup.py` and want an editable install).
3.  Execute the orchestrator module:
    ```bash
    python -m prompthelix.orchestrator
    ```
    This will print output to the console, showing the initialization steps, progress through generations, and information about the fittest prompts found.

## Future Directions
(Placeholder for outlining future development plans, such as full LLM integration, database setup, UI development, etc.)
