# PromptHelix

A Python framework for AI prompt generation and optimization using a Prompt DNA System.

## Project Structure

-   `prompthelix/agents/`: Contains different types of AI agents (Architect, Critic, etc.).
-   `prompthelix/api/`: Defines the FastAPI endpoints and routing.
-   `prompthelix/config.py`: Application configuration settings.
-   `prompthelix/docs/`: Project documentation.
    -   `agent_specifications.md`: Detailed specifications for each agent.
-   `prompthelix/evaluation/`: Modules for evaluating prompt performance (placeholder).
-   `prompthelix/genetics/`: Core logic for the genetic algorithm (chromosomes, operators, population).
-   `prompthelix/main.py`: Main FastAPI application entry point.
-   `prompthelix/models/`: Data models (SQLAlchemy or Pydantic, currently placeholders).
-   `prompthelix/services/`: Business logic and services (placeholder).
-   `prompthelix/tests/`: Unit and integration tests.
    -   `unit/`: Contains unit tests for individual components, including each agent.
-   `prompthelix/utils/`: Utility functions and helpers (placeholder).
-   `setup.py`: Project setup script.
-   `requirements.txt`: Project dependencies.
-   `Dockerfile`: Docker configuration for containerization.

## Implemented Agents

The PromptHelix system is designed around a collection of specialized AI agents that collaborate to generate, refine, and evaluate prompts.

-   **`PromptArchitectAgent`**: Designs the initial genetic structure of prompts based on user requirements, system goals, or existing successful prompt patterns.
-   **`PromptCriticAgent`**: Evaluates and critiques prompts based on their structure, content, and adherence to best practices, without necessarily executing them (acting as a "static analyzer").
-   **`StyleOptimizerAgent`**: Refines prompts to enhance their style, tone, clarity, and persuasiveness, often based on specific target audience or desired communication effect.
-   **`ResultsEvaluatorAgent`**: Assesses the quality, relevance, and effectiveness of the outputs generated by an LLM in response to a given prompt.
-   **`MetaLearnerAgent`**: Analyzes the overall performance of the prompt generation and optimization process over time to provide higher-level guidance and adapt strategies.
-   **`DomainExpertAgent`**: Provides domain-specific knowledge, constraints, terminology, and evaluation criteria to other agents.

### Agent Functionality Notes
The current implementations of these agents are functional placeholders. They utilize mock data (e.g., for templates, critique rules, style rules, domain knowledge) and simplified internal logic. This approach is intended to establish the foundational framework of the multi-agent system and demonstrate the intended interactions and data flows. Future development will involve replacing mock data with configurable sources and implementing more sophisticated algorithms and machine learning models within each agent.

## Testing

Unit tests for the core placeholder functionalities of each agent are located in the `prompthelix/tests/unit/` directory. Each agent has its own test file (e.g., `test_architect_agent.py`, `test_critic_agent.py`, etc.) that verifies its basic operations, such as initialization, loading of mock data, and processing of example requests.

To run the tests, navigate to the root directory of the project and use a test runner like Python's `unittest` module. For example:
```bash
python -m unittest discover -s prompthelix/tests/unit
```
(Further details on test execution and integration tests will be added as the project matures.)

## Future Directions
(Placeholder for outlining future development plans, such as full LLM integration, database setup, UI development, etc.)
